{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acc82414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pathlib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c693c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = 'https://storage.googleapis.com/download.tensorflow.org/data/stack_overflow_16k.tar.gz'\n",
    "\n",
    "dataset_dir = utils.get_file(\n",
    "    origin=data_url,\n",
    "    untar=True,\n",
    "    cache_dir='stack_overflow',\n",
    "    cache_subdir='')\n",
    "\n",
    "dataset_dir = pathlib.Path(dataset_dir).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a03095a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('/tmp/.keras/README.md'),\n",
       " WindowsPath('/tmp/.keras/stack_overflow_16k.tar.gz'),\n",
       " WindowsPath('/tmp/.keras/test'),\n",
       " WindowsPath('/tmp/.keras/train')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dataset_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b1edc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('/tmp/.keras/train/csharp'),\n",
       " WindowsPath('/tmp/.keras/train/java'),\n",
       " WindowsPath('/tmp/.keras/train/javascript'),\n",
       " WindowsPath('/tmp/.keras/train/python')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = dataset_dir/'train'\n",
    "list(train_dir.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "357fc251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "why does this blank program print true x=true.def stupid():.    x=false.stupid().print x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_file = train_dir/'python/1755.txt'\n",
    "\n",
    "with open(sample_file) as f:\n",
    "  print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f89fd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 6400 files for training.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "raw_train_ds = utils.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15d06f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a91ad456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int32)>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7da6130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  b'\"function expected e...'\n",
      "Label: 2\n",
      "Question:  b'\"find highest double...'\n",
      "Label: 1\n",
      "Question:  b'\"exception of type \\'...'\n",
      "Label: 0\n",
      "Question:  b'why does print() on ...'\n",
      "Label: 3\n",
      "Question:  b'\"can i use node.chil...'\n",
      "Label: 2\n",
      "Question:  b'\"how do i convert a ...'\n",
      "Label: 3\n",
      "Question:  b'\"find index of a str...'\n",
      "Label: 1\n",
      "Question:  b'\"blank code not work...'\n",
      "Label: 2\n",
      "Question:  b'\"ifs and arraylists ...'\n",
      "Label: 1\n",
      "Question:  b'blank annotation ele...'\n",
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "for text_batch, label_batch in raw_train_ds.take(1):\n",
    "  for i in range(10):\n",
    "    print(\"Question: \", text_batch.numpy()[i][:20] + b\"...\")\n",
    "    print(\"Label:\", label_batch.numpy()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "743e505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0 corresponds to csharp\n",
      "Label 1 corresponds to java\n",
      "Label 2 corresponds to javascript\n",
      "Label 3 corresponds to python\n"
     ]
    }
   ],
   "source": [
    "for i, label in enumerate(raw_train_ds.class_names):\n",
    "  print(\"Label\", i, \"corresponds to\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "030db252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n",
      "Using 1600 files for validation.\n"
     ]
    }
   ],
   "source": [
    "# Create a validation set.\n",
    "raw_val_ds = utils.text_dataset_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d73631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dir = dataset_dir/'test'\n",
    "\n",
    "# Create a test set.\n",
    "raw_test_ds = utils.text_dataset_from_directory(\n",
    "    test_dir,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3c7e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "\n",
    "binary_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e84671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 250\n",
    "\n",
    "int_vectorize_layer = TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e70f73c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a text-only dataset (without labels), then call `TextVectorization.adapt`.\n",
    "train_text = raw_train_ds.map(lambda text, labels: text)\n",
    "binary_vectorize_layer.adapt(train_text)\n",
    "int_vectorize_layer.adapt(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11024cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question tf.Tensor(b'\"can i use node.childnodes in the if clause? can i do..if (node.childnodes) {.  // do something.}...instead of ..if (node.haschildnodes()) {.  // do something.}...i tried it, and it works. i tried !div.childnodes on a div element with stuff inside it and this returned the boolean false. it looks like it\\'s working, but are there any traps that i\\'m overlooking here?\"\\n', shape=(), dtype=string)\n",
      "Label tf.Tensor(2, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def binary_vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return binary_vectorize_layer(text), label\n",
    "\n",
    "def int_vectorize_text(text, label):\n",
    "  text = tf.expand_dims(text, -1)\n",
    "  return int_vectorize_layer(text), label\n",
    "\n",
    "# Retrieve a batch (of 32 reviews and labels) from the dataset.\n",
    "text_batch, label_batch = next(iter(raw_train_ds))\n",
    "first_question, first_label = text_batch[0], label_batch[0]\n",
    "print(\"Question\", first_question)\n",
    "print(\"Label\", first_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8811430a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.BatchDataset"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(raw_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d38a9f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_train_ds = raw_train_ds.map(binary_vectorize_text)\n",
    "binary_val_ds = raw_val_ds.map(binary_vectorize_text)\n",
    "binary_test_ds = raw_test_ds.map(binary_vectorize_text)\n",
    "\n",
    "int_train_ds = raw_train_ds.map(int_vectorize_text)\n",
    "int_val_ds = raw_val_ds.map(int_vectorize_text)\n",
    "int_test_ds = raw_test_ds.map(int_vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "642fe4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 1.1184 - accuracy: 0.6559 - val_loss: 0.9154 - val_accuracy: 0.7756\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.7781 - accuracy: 0.8177 - val_loss: 0.7508 - val_accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.6265 - accuracy: 0.8642 - val_loss: 0.6657 - val_accuracy: 0.8125\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 13s 65ms/step - loss: 0.5333 - accuracy: 0.8850 - val_loss: 0.6110 - val_accuracy: 0.8281\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 8s 38ms/step - loss: 0.4675 - accuracy: 0.9031 - val_loss: 0.5749 - val_accuracy: 0.8331\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 7s 31ms/step - loss: 0.4173 - accuracy: 0.9177 - val_loss: 0.5477 - val_accuracy: 0.8369\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 6s 28ms/step - loss: 0.3773 - accuracy: 0.9281 - val_loss: 0.5279 - val_accuracy: 0.8388\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 5s 25ms/step - loss: 0.3443 - accuracy: 0.9352 - val_loss: 0.5126 - val_accuracy: 0.8400\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.3158 - accuracy: 0.9423 - val_loss: 0.5002 - val_accuracy: 0.8394\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.2916 - accuracy: 0.9505 - val_loss: 0.4905 - val_accuracy: 0.8419\n"
     ]
    }
   ],
   "source": [
    "binary_model = tf.keras.Sequential([layers.Dense(4)])\n",
    "\n",
    "binary_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = binary_model.fit(\n",
    "    binary_train_ds, validation_data=binary_val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8947e56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.9573 - accuracy: 0.6628 - val_loss: 0.6393 - val_accuracy: 0.7869\n",
      "Epoch 2/10\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.4544 - accuracy: 0.8559 - val_loss: 0.4864 - val_accuracy: 0.8231\n",
      "Epoch 3/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.2682 - accuracy: 0.9214 - val_loss: 0.4606 - val_accuracy: 0.8363\n",
      "Epoch 4/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.1630 - accuracy: 0.9606 - val_loss: 0.4797 - val_accuracy: 0.8369\n",
      "Epoch 5/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.0995 - accuracy: 0.9811 - val_loss: 0.5170 - val_accuracy: 0.8338\n",
      "Epoch 6/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.0614 - accuracy: 0.9912 - val_loss: 0.5682 - val_accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "200/200 [==============================] - 5s 26ms/step - loss: 0.0384 - accuracy: 0.9959 - val_loss: 0.6125 - val_accuracy: 0.8294\n",
      "Epoch 8/10\n",
      "200/200 [==============================] - 6s 27ms/step - loss: 0.0242 - accuracy: 0.9984 - val_loss: 0.6621 - val_accuracy: 0.8281\n",
      "Epoch 9/10\n",
      "200/200 [==============================] - 6s 30ms/step - loss: 0.0156 - accuracy: 0.9991 - val_loss: 0.7148 - val_accuracy: 0.8213\n",
      "Epoch 10/10\n",
      "200/200 [==============================] - 5s 27ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.7578 - val_accuracy: 0.8225\n"
     ]
    }
   ],
   "source": [
    "binary_model1 = tf.keras.Sequential([\n",
    "    layers.Dense(6),\n",
    "    layers.Dense(5),\n",
    "    layers.Dense(4)\n",
    "])\n",
    "\n",
    "binary_model1.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "history = binary_model1.fit(\n",
    "    binary_train_ds, validation_data=binary_val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01e69635",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, num_labels):\n",
    "  model = tf.keras.Sequential([\n",
    "      layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "      layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "      layers.GlobalMaxPooling1D(),\n",
    "      layers.Dense(num_labels)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e6346a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "200/200 [==============================] - 12s 51ms/step - loss: 1.1343 - accuracy: 0.5184 - val_loss: 0.7427 - val_accuracy: 0.7106\n",
      "Epoch 2/5\n",
      "200/200 [==============================] - 10s 47ms/step - loss: 0.6086 - accuracy: 0.7650 - val_loss: 0.5412 - val_accuracy: 0.7944\n",
      "Epoch 3/5\n",
      "200/200 [==============================] - 10s 50ms/step - loss: 0.3634 - accuracy: 0.8852 - val_loss: 0.4818 - val_accuracy: 0.8094\n",
      "Epoch 4/5\n",
      "200/200 [==============================] - 10s 51ms/step - loss: 0.1967 - accuracy: 0.9555 - val_loss: 0.4833 - val_accuracy: 0.8194\n",
      "Epoch 5/5\n",
      "200/200 [==============================] - 10s 48ms/step - loss: 0.0954 - accuracy: 0.9837 - val_loss: 0.5056 - val_accuracy: 0.8138\n"
     ]
    }
   ],
   "source": [
    "# `vocab_size` is `VOCAB_SIZE + 1` since `0` is used additionally for padding.\n",
    "int_model = create_model(vocab_size=VOCAB_SIZE + 1, num_labels=4)\n",
    "int_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "history = int_model.fit(int_train_ds, validation_data=int_val_ds, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28bbd756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model on binary vectorized data:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 4)                 40004     \n",
      "=================================================================\n",
      "Total params: 40,004\n",
      "Trainable params: 40,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear model on binary vectorized data:\")\n",
    "print(binary_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10a6d002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet model on int vectorized data:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          640064    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 64)          20544     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 660,868\n",
      "Trainable params: 660,868\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"ConvNet model on int vectorized data:\")\n",
    "print(int_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40ca7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 18ms/step - loss: 0.5187 - accuracy: 0.8139\n",
      "250/250 [==============================] - 6s 21ms/step - loss: 0.5266 - accuracy: 0.8096\n",
      "Binary model accuracy: 81.39%\n",
      "Int model accuracy: 80.96%\n"
     ]
    }
   ],
   "source": [
    "binary_loss, binary_accuracy = binary_model.evaluate(binary_test_ds)\n",
    "int_loss, int_accuracy = int_model.evaluate(int_test_ds)\n",
    "\n",
    "print(\"Binary model accuracy: {:2.2%}\".format(binary_accuracy))\n",
    "print(\"Int model accuracy: {:2.2%}\".format(int_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be05345c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 19ms/step - loss: 0.8412 - accuracy: 0.7871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8411602973937988, 0.7871249914169312]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model1.evaluate(binary_test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75a65a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 19ms/step - loss: 0.5187 - accuracy: 0.8139 0s - loss: 0.5182 - accu\n",
      "Accuracy: 81.39%\n"
     ]
    }
   ],
   "source": [
    "export_model = tf.keras.Sequential(\n",
    "    [binary_vectorize_layer, binary_model,\n",
    "     layers.Activation('sigmoid')])\n",
    "\n",
    "export_model.compile(\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# Test it with `raw_test_ds`, which yields raw strings\n",
    "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
    "print(\"Accuracy: {:2.2%}\".format(binary_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de243c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_string_labels(predicted_scores_batch):\n",
    "  predicted_int_labels = tf.argmax(predicted_scores_batch, axis=1)\n",
    "  predicted_labels = tf.gather(raw_train_ds.class_names, predicted_int_labels)\n",
    "  return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06f6a3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  how do I extract keys from a dict into a list?\n",
      "Predicted label:  b'python'\n",
      "Question:  debug public static void main(string[] args) {...}\n",
      "Predicted label:  b'java'\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    \"how do I extract keys from a dict into a list?\",  # 'python'\n",
    "    \"debug public static void main(string[] args) {...}\",  # 'java'\n",
    "]\n",
    "predicted_scores = export_model.predict(inputs)\n",
    "predicted_labels = get_string_labels(predicted_scores)\n",
    "for input, label in zip(inputs, predicted_labels):\n",
    "  print(\"Question: \", input)\n",
    "  print(\"Predicted label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddaa7b9",
   "metadata": {},
   "source": [
    "# Exemplo 2\n",
    "Irrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627599c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
